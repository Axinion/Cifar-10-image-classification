{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-07T14:20:24.050848Z","iopub.status.busy":"2021-11-07T14:20:24.050235Z","iopub.status.idle":"2021-11-07T14:20:25.981316Z","shell.execute_reply":"2021-11-07T14:20:25.980451Z","shell.execute_reply.started":"2021-11-07T14:20:24.050757Z"},"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","\n","import tensorflow_addons as tfa\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import wandb\n","from wandb.keras import WandbCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-07T14:20:25.986844Z","iopub.status.busy":"2021-11-07T14:20:25.985232Z","iopub.status.idle":"2021-11-07T14:20:32.935765Z","shell.execute_reply":"2021-11-07T14:20:32.93487Z","shell.execute_reply.started":"2021-11-07T14:20:25.986813Z"},"trusted":true},"outputs":[],"source":["wandb.init(project=\"Conv-Mixer\",name=\"ConvMixer\",resume=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-07T14:20:32.94326Z","iopub.status.busy":"2021-11-07T14:20:32.940961Z","iopub.status.idle":"2021-11-07T14:20:32.951675Z","shell.execute_reply":"2021-11-07T14:20:32.950962Z","shell.execute_reply.started":"2021-11-07T14:20:32.9432Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.001\n","weight_decay = 0.0001\n","batch_size = 128\n","num_epochs = 32"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset, test_dataset = dataset['train'], dataset['test']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#create a function to normalize and resize the images\n","def normalize_and_resize(image, label):\n","    image=tf.cast(image, tf.float32)\n","    image=tf.divide(image, 255)\n","    image=tf.image.resize(image, [28,28])\n","    return image, label\n","\n","#create a function to augment the images\n","def augment(image, label):\n","    image=tf.image.random_flip_left_right(image)\n","    image=tf.image.random_flip_up_down(image)\n","    image=tf.image.random_brightness(image, max_delta=0.5)\n","    image=tf.image.random_contrast(image, lower=0.2, upper=1.8)\n","    image=tf.image.random_hue(image, max_delta=0.2)\n","    image=tf.image.random_saturation(image, lower=0.2, upper=1.8)\n","    return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#modify the train and test datasets using the function\n","train_dataset=train_dataset.map(normalize_and_resize).cache().map(augment).shuffle(1000).batch(64).repeat()\n","test_dataset=test_dataset.map(normalize_and_resize).cache().batch(64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#This function performs the activation function and the post activation batch normalization\n","def activation_normalization_layer(x):\n","    \"\"\"\n","    x: input tensor\n","    \"\"\"\n","    x=keras.layers.Activation('gelu')(x)\n","    x=keras.layers.BatchNormalization()(x)\n","    return x\n","\n","\n","#This function creates the patch embeddings\n","def patch_conv_layer(x, filters, patch_size):\n","    \"\"\"\n","    x: input tensor\n","    filters: number of filters or hidden dimension\n","    patch_size: the patch size which in this case determines the kernel size and stride\n","    \"\"\"\n","    x=keras.layers.Conv2D(filters=filters, kernel_size=patch_size, strides=patch_size)(x)\n","    x=activation_normalization_layer(x)\n","    return x\n","\n","\n","#This is the main ConvMixer layer which is repeated \"depth\" times\n","def conv_mixer_layer(x, filters, kernel_size):\n","    \"\"\"\n","    x: input tensor\n","    filters: number of filters or hidden dimension\n","    kernel_size: the kernel size\n","    \"\"\"\n","    #residual depthwise convolution\n","    initial=x\n","    x=keras.layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n","    x=activation_normalization_layer(x)\n","    x=keras.layers.Concatenate()([x, initial])\n","    \n","    #pointwise convolution 1x1\n","    x=keras.layers.Conv2D(filters=filters, kernel_size=1, padding=\"same\")(x) #1x1 because pointwise\n","    x=activation_normalization_layer(x)\n","    \n","    return x\n","    \n","def conv_mixer_model(image_size=28,filters=256,depth=8,kernel_size=5,patch_size=2,num_classes=10):\n","    \"\"\"\n","    image_size: the size of the image\n","    filters: number of filters or hidden dimension\n","    depth: the number of times the conv_mixer_layer is repeated\n","    kernel_size: the kernel size\n","    patch_size: the patch size\n","    num_classes: the number of classes in the output\n","    \"\"\"\n","    inputs=keras.Input(shape=(image_size,image_size,3))\n","    \n","    #get the patches\n","    x=patch_conv_layer(inputs, filters, patch_size)\n","    \n","    #conv mixer block repeated 'depth' times\n","    for _ in range(depth):\n","        x=conv_mixer_layer(x, filters, kernel_size)\n","    \n","    #pooling and softmax\n","    x=keras.layers.GlobalAveragePooling2D()(x)\n","    output=keras.layers.Dense(num_classes,activation=\"softmax\")(x)\n","    \n","    model=keras.Model(inputs=inputs, outputs=output)\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-07T14:20:35.781848Z","iopub.status.busy":"2021-11-07T14:20:35.781076Z","iopub.status.idle":"2021-11-07T14:20:35.792542Z","shell.execute_reply":"2021-11-07T14:20:35.791846Z","shell.execute_reply.started":"2021-11-07T14:20:35.781712Z"},"trusted":true},"outputs":[],"source":["def run(model):\n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=learning_rate, weight_decay=weight_decay\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","\n","    history = model.fit(\n","        train_dataset,\n","        validation_data=test_dataset,\n","        epochs=num_epochs,\n","        steps_per_epoch=60000//64,\n","        callbacks=[WandbCallback()],\n","    )\n","\n","    return history, model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-07T14:20:35.793705Z","iopub.status.busy":"2021-11-07T14:20:35.793512Z","iopub.status.idle":"2021-11-07T14:29:50.153714Z","shell.execute_reply":"2021-11-07T14:29:50.15294Z","shell.execute_reply.started":"2021-11-07T14:20:35.793682Z"},"trusted":true},"outputs":[],"source":["model = conv_mixer_model()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history, model = run(model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
